{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: Tesla K20c (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.regularizers import l2, activity_l2,l1\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from scipy import misc\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model with VGG16 feature extractors, set trainable false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel( output_dim ):\n",
    "    # output_dim: the number of classes (int)\n",
    "    # return: compiled model (keras.engine.training.Model)\n",
    "    \n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    vgg_out = vgg_model.layers[-2].output \n",
    "    \n",
    "    vgg_out = Dropout(0.25)(vgg_out)\n",
    "    softmax = Dense( output_dim, activation=\"softmax\", W_regularizer = l2(0.01))( vgg_out )\n",
    "    \n",
    "\n",
    "    tl_model = Model( input=vgg_model.input, output=softmax )\n",
    "    # Transfer Learning\n",
    "    for layer in tl_model.layers[0:-1]:\n",
    "        layer.trainable = False            \n",
    "\n",
    "    tl_model.compile(loss= \"categorical_crossentropy\", optimizer=\"adadelta\", metrics=[\"acc\"])\n",
    "    \n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all images into 'album'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadImages(path = '/mnt/cube/UT_/Urban_tribes/'):\n",
    "    album = {}\n",
    "    for item in listdir(path):\n",
    "        category = item[0:4]\n",
    "        if category == \".ipy\":\n",
    "            continue\n",
    "        if category not in album:\n",
    "            album[category] = []\n",
    "        \n",
    "        img = load_img(path+item)\n",
    "        img = img_to_array(img)\n",
    "        img = misc.imresize(img, (224, 224))\n",
    "        img = scipy.misc.imrotate(img, 180)\n",
    "        album[category].append(img)\n",
    "    return album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "album = loadImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(album['goth'][0][:, :, 0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 'album' into dataset\n",
    "Album is split into training and testing input/outputs according to number of examples attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(album, n_train, n_test):\n",
    "    trn_inp = []\n",
    "    trn_out = []\n",
    "    tst_inp = []\n",
    "    tst_out = []    \n",
    "    keys = album.keys()\n",
    "    for key in keys:\n",
    "        examples = album[key]\n",
    "        l = len(examples)\n",
    "        idx = np.random.choice(l, n_train+n_test)\n",
    "        for i in idx[:-n_test]:\n",
    "            trn_inp.append(examples[i])\n",
    "            trn_out.append(keys.index(key))\n",
    "        for i in idx[-n_test:]:\n",
    "            tst_inp.append(examples[i])\n",
    "            tst_out.append(keys.index(key))\n",
    "    return [trn_inp, trn_out, tst_inp, tst_out]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(album['bike'][0][:, :, 0])\n",
    "# # plt.show()\n",
    "# album.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samCat = 16\n",
    "dataset = make_dataset(album, samCat, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX = np.array(dataset[0])\n",
    "trainY = np.array(dataset[1])\n",
    "\n",
    "# Now shuffle the training data and swapaxes\n",
    "idx = np.random.choice(len(trainX), len(trainX))\n",
    "trainX = trainX[idx]\n",
    "trainY = trainY[idx]\n",
    "\n",
    "trainX = preprocess_input(np.float64(trainX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "\n",
    "# Only swapaxes for testing data\n",
    "testX = np.array(dataset[2])\n",
    "testY = np.array(dataset[3])\n",
    "\n",
    "testX = preprocess_input(np.float64(testX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "testY = np_utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(trainX[10][0, :, :])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = getModel(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 176 samples\n",
      "Epoch 1/30\n",
      "176/176 [==============================] - 8s - loss: 3.6353 - acc: 0.1080 - val_loss: 2.9905 - val_acc: 0.1364\n",
      "Epoch 2/30\n",
      "176/176 [==============================] - 8s - loss: 2.2463 - acc: 0.3523 - val_loss: 2.7017 - val_acc: 0.2273\n",
      "Epoch 3/30\n",
      "176/176 [==============================] - 8s - loss: 1.6208 - acc: 0.5227 - val_loss: 2.5890 - val_acc: 0.2443\n",
      "Epoch 4/30\n",
      "176/176 [==============================] - 8s - loss: 1.2152 - acc: 0.6761 - val_loss: 2.5517 - val_acc: 0.3182\n",
      "Epoch 5/30\n",
      "176/176 [==============================] - 8s - loss: 0.9518 - acc: 0.7727 - val_loss: 2.4422 - val_acc: 0.3182\n",
      "Epoch 6/30\n",
      "176/176 [==============================] - 8s - loss: 0.8800 - acc: 0.7955 - val_loss: 2.4328 - val_acc: 0.3182\n",
      "Epoch 7/30\n",
      "176/176 [==============================] - 8s - loss: 0.6697 - acc: 0.8864 - val_loss: 2.4128 - val_acc: 0.3352\n",
      "Epoch 8/30\n",
      "176/176 [==============================] - 8s - loss: 0.6196 - acc: 0.8977 - val_loss: 2.4710 - val_acc: 0.3125\n",
      "Epoch 9/30\n",
      "176/176 [==============================] - 8s - loss: 0.6029 - acc: 0.8920 - val_loss: 2.4185 - val_acc: 0.3580\n",
      "Epoch 10/30\n",
      "176/176 [==============================] - 8s - loss: 0.5091 - acc: 0.9545 - val_loss: 2.4539 - val_acc: 0.3295\n",
      "Epoch 11/30\n",
      "176/176 [==============================] - 8s - loss: 0.4872 - acc: 0.9489 - val_loss: 2.3905 - val_acc: 0.3693\n",
      "Epoch 12/30\n",
      "176/176 [==============================] - 8s - loss: 0.4064 - acc: 0.9716 - val_loss: 2.4054 - val_acc: 0.3523\n",
      "Epoch 13/30\n",
      "176/176 [==============================] - 8s - loss: 0.4357 - acc: 0.9261 - val_loss: 2.4024 - val_acc: 0.3636\n",
      "Epoch 14/30\n",
      "176/176 [==============================] - 8s - loss: 0.3598 - acc: 0.9773 - val_loss: 2.3905 - val_acc: 0.3636\n",
      "Epoch 15/30\n",
      "176/176 [==============================] - 8s - loss: 0.3563 - acc: 0.9830 - val_loss: 2.4028 - val_acc: 0.3807\n",
      "Epoch 16/30\n",
      "176/176 [==============================] - 8s - loss: 0.3285 - acc: 0.9886 - val_loss: 2.3933 - val_acc: 0.3807\n",
      "Epoch 17/30\n",
      "176/176 [==============================] - 8s - loss: 0.3103 - acc: 0.9886 - val_loss: 2.4030 - val_acc: 0.3807\n",
      "Epoch 18/30\n",
      "176/176 [==============================] - 8s - loss: 0.2928 - acc: 0.9886 - val_loss: 2.4017 - val_acc: 0.3864\n",
      "Epoch 19/30\n",
      "176/176 [==============================] - 8s - loss: 0.2892 - acc: 0.9943 - val_loss: 2.3932 - val_acc: 0.3864\n",
      "Epoch 20/30\n",
      "176/176 [==============================] - 8s - loss: 0.2884 - acc: 0.9886 - val_loss: 2.4096 - val_acc: 0.3636\n",
      "Epoch 21/30\n",
      "176/176 [==============================] - 8s - loss: 0.2630 - acc: 1.0000 - val_loss: 2.3969 - val_acc: 0.3864\n",
      "Epoch 22/30\n",
      "176/176 [==============================] - 8s - loss: 0.2684 - acc: 0.9886 - val_loss: 2.4181 - val_acc: 0.3977\n",
      "Epoch 23/30\n",
      "176/176 [==============================] - 8s - loss: 0.2535 - acc: 1.0000 - val_loss: 2.3876 - val_acc: 0.3693\n",
      "Epoch 24/30\n",
      "176/176 [==============================] - 8s - loss: 0.2439 - acc: 1.0000 - val_loss: 2.3846 - val_acc: 0.3920\n",
      "Epoch 25/30\n",
      "176/176 [==============================] - 8s - loss: 0.2422 - acc: 1.0000 - val_loss: 2.4336 - val_acc: 0.4034\n",
      "Epoch 26/30\n",
      "176/176 [==============================] - 8s - loss: 0.2410 - acc: 1.0000 - val_loss: 2.4245 - val_acc: 0.3920\n",
      "Epoch 27/30\n",
      "176/176 [==============================] - 8s - loss: 0.2285 - acc: 1.0000 - val_loss: 2.4211 - val_acc: 0.3977\n",
      "Epoch 28/30\n",
      "176/176 [==============================] - 8s - loss: 0.2178 - acc: 1.0000 - val_loss: 2.4199 - val_acc: 0.3864\n",
      "Epoch 29/30\n",
      "176/176 [==============================] - 8s - loss: 0.2146 - acc: 1.0000 - val_loss: 2.4315 - val_acc: 0.3920\n",
      "Epoch 30/30\n",
      "176/176 [==============================] - 8s - loss: 0.2085 - acc: 1.0000 - val_loss: 2.4507 - val_acc: 0.4034\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, batch_size = 16, nb_epoch = 30, validation_data = (testX, testY), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss for %d samples per category' % samCat)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy for %d samples per category' % samCat)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_acc: 0.2273 2 sample\n",
    "        0.25  4 sample\n",
    "        0.3182 8 sample\n",
    "        0.4034 16 sample\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
