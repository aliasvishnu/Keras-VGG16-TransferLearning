{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.regularizers import l2, activity_l2,l1\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from scipy import misc\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model with VGG16 feature extractors, set trainable false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel( output_dim ):\n",
    "    # output_dim: the number of classes (int)\n",
    "    # return: compiled model (keras.engine.training.Model)\n",
    "    \n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    vgg_out = vgg_model.layers[-2].output \n",
    "    \n",
    "\n",
    "    softmax = Dense( output_dim, activation=\"softmax\", W_regularizer = l2(0.02))( vgg_out )\n",
    "\n",
    "    tl_model = Model( input=vgg_model.input, output=softmax )\n",
    "    # Transfer Learning\n",
    "    for layer in tl_model.layers[0:-1]:\n",
    "        layer.trainable = False            \n",
    "\n",
    "    tl_model.compile(loss= \"categorical_crossentropy\", optimizer=\"adadelta\", \n",
    "                     metrics=[\"acc\"])\n",
    "    \n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all images into 'album'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadImages(path = '/mnt/cube/UT_/Urban_tribes/'):\n",
    "    album = {}\n",
    "    for item in listdir(path):\n",
    "        category = item[0:4]\n",
    "        if category == \".ipy\":\n",
    "            continue\n",
    "        if category not in album:\n",
    "            album[category] = []\n",
    "        \n",
    "        img = load_img(path+item)\n",
    "        img = img_to_array(img)\n",
    "        img = misc.imresize(img, (224, 224))\n",
    "        img = scipy.misc.imrotate(img, 180)\n",
    "        album[category].append(img)\n",
    "    return album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'album' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ed30b0b0b56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malbum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'goth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'album' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(album['goth'][0][:, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 'album' into dataset\n",
    "Album is split into training and testing input/outputs according to number of examples attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(album, numExamples):\n",
    "    trn_inp = []\n",
    "    trn_out = []\n",
    "    tst_inp = []\n",
    "    tst_out = []\n",
    "    keys = album.keys()\n",
    "    for key in keys:\n",
    "        examples = album[key]\n",
    "        l = len(examples)\n",
    "        idx = np.random.choice(l, numExamples+5)\n",
    "        for i in idx[:-5]:\n",
    "            trn_inp.append(examples[i])\n",
    "            trn_out.append(keys.index(key))\n",
    "        for i in idx[-5:]:\n",
    "            tst_inp.append(examples[i])\n",
    "            tst_out.append(keys.index(key))\n",
    "    return [trn_inp, trn_out, tst_inp, tst_out]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "album = loadImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surf',\n",
       " 'goth',\n",
       " 'hiph',\n",
       " 'form',\n",
       " 'club',\n",
       " 'heav',\n",
       " 'othe',\n",
       " 'bike',\n",
       " 'rave',\n",
       " 'hips',\n",
       " 'coun']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(album['bike'][0][:, :, 0])\n",
    "# plt.show()\n",
    "album.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(album, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX = np.array(dataset[0])\n",
    "trainY = np.array(dataset[1])\n",
    "\n",
    "# Now shuffle the training data and swapaxes\n",
    "idx = np.random.choice(len(trainX), len(trainX))\n",
    "trainX = trainX[idx]\n",
    "trainY = trainY[idx]\n",
    "\n",
    "trainX = preprocess_input(np.float64(trainX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "\n",
    "# Only swapaxes for testing data\n",
    "testX = np.array(dataset[2])\n",
    "testY = np.array(dataset[3])\n",
    "\n",
    "testX = preprocess_input(np.float64(testX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "testY = np_utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(trainX[10][0, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = getModel(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 55 samples\n",
      "Epoch 1/30\n",
      "176/176 [==============================] - 11s - loss: 3.0697 - acc: 0.2273 - val_loss: 3.1058 - val_acc: 0.1818\n",
      "Epoch 2/30\n",
      "176/176 [==============================] - 10s - loss: 1.7716 - acc: 0.5966 - val_loss: 2.8761 - val_acc: 0.1455\n",
      "Epoch 3/30\n",
      "176/176 [==============================] - 11s - loss: 1.2621 - acc: 0.8011 - val_loss: 2.7514 - val_acc: 0.2364\n",
      "Epoch 4/30\n",
      "176/176 [==============================] - 10s - loss: 0.9856 - acc: 0.8977 - val_loss: 2.7162 - val_acc: 0.2727\n",
      "Epoch 5/30\n",
      "176/176 [==============================] - 11s - loss: 0.8262 - acc: 0.9148 - val_loss: 2.6335 - val_acc: 0.2545\n",
      "Epoch 6/30\n",
      "176/176 [==============================] - 10s - loss: 0.7228 - acc: 0.9545 - val_loss: 2.5927 - val_acc: 0.2727\n",
      "Epoch 7/30\n",
      " 96/176 [===============>..............] - ETA: 3s - loss: 0.6661 - acc: 0.9583"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, batch_size = 16, nb_epoch = 30, validation_data = (testX, testY), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
