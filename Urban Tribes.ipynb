{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: Tesla K20c (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.regularizers import l2, activity_l2,l1\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from scipy import misc\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model with VGG16 feature extractors, set trainable false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel( output_dim ):\n",
    "    # output_dim: the number of classes (int)\n",
    "    # return: compiled model (keras.engine.training.Model)\n",
    "    \n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    vgg_out = vgg_model.layers[-2].output \n",
    "    \n",
    "    vgg_out = Dropout(0.25)(vgg_out)\n",
    "    softmax = Dense( output_dim, activation=\"softmax\", W_regularizer = l2(0.01))( vgg_out )\n",
    "    \n",
    "\n",
    "    tl_model = Model( input=vgg_model.input, output=softmax )\n",
    "    # Transfer Learning\n",
    "    for layer in tl_model.layers[0:-1]:\n",
    "        layer.trainable = False            \n",
    "\n",
    "    tl_model.compile(loss= \"categorical_crossentropy\", optimizer=\"adadelta\", metrics=[\"acc\"])\n",
    "    \n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all images into 'album'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadImages(path = '/mnt/cube/UT_/Urban_tribes/'):\n",
    "    album = {}\n",
    "    for item in listdir(path):\n",
    "        category = item[0:4]\n",
    "        if category == \".ipy\":\n",
    "            continue\n",
    "        if category not in album:\n",
    "            album[category] = []\n",
    "        \n",
    "        img = load_img(path+item)\n",
    "        img = img_to_array(img)\n",
    "        img = misc.imresize(img, (224, 224))\n",
    "        img = scipy.misc.imrotate(img, 180)\n",
    "        album[category].append(img)\n",
    "    return album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "album = loadImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(album['goth'][0][:, :, 0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 'album' into dataset\n",
    "Album is split into training and testing input/outputs according to number of examples attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(album, n_train, n_test):\n",
    "    trn_inp = []\n",
    "    trn_out = []\n",
    "    tst_inp = []\n",
    "    tst_out = []    \n",
    "    keys = album.keys()\n",
    "    for key in keys:\n",
    "        examples = album[key]\n",
    "        l = len(examples)\n",
    "        idx = np.random.choice(l, n_train+n_test)\n",
    "        for i in idx[:-n_test]:\n",
    "            trn_inp.append(examples[i])\n",
    "            trn_out.append(keys.index(key))\n",
    "        for i in idx[-n_test:]:\n",
    "            tst_inp.append(examples[i])\n",
    "            tst_out.append(keys.index(key))\n",
    "    return [trn_inp, trn_out, tst_inp, tst_out]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(album['bike'][0][:, :, 0])\n",
    "# # plt.show()\n",
    "# album.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samCat = 70\n",
    "dataset = make_dataset(album, samCat, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX = np.array(dataset[0])\n",
    "trainY = np.array(dataset[1])\n",
    "\n",
    "# Now shuffle the training data and swapaxes\n",
    "idx = np.random.choice(len(trainX), len(trainX))\n",
    "trainX = trainX[idx]\n",
    "trainY = trainY[idx]\n",
    "\n",
    "trainX = preprocess_input(np.float64(trainX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "\n",
    "# Only swapaxes for testing data\n",
    "testX = np.array(dataset[2])\n",
    "testY = np.array(dataset[3])\n",
    "\n",
    "testX = preprocess_input(np.float64(testX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "testY = np_utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(trainX[10][0, :, :])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = getModel(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 770 samples, validate on 330 samples\n",
      "Epoch 1/30\n",
      "770/770 [==============================] - 25s - loss: 2.7576 - acc: 0.2481 - val_loss: 2.1842 - val_acc: 0.3758\n",
      "Epoch 2/30\n",
      "770/770 [==============================] - 25s - loss: 1.5954 - acc: 0.5792 - val_loss: 2.0375 - val_acc: 0.4576\n",
      "Epoch 3/30\n",
      "770/770 [==============================] - 25s - loss: 1.2283 - acc: 0.6883 - val_loss: 1.7557 - val_acc: 0.5242\n",
      "Epoch 4/30\n",
      "770/770 [==============================] - 25s - loss: 0.9588 - acc: 0.7727 - val_loss: 1.7171 - val_acc: 0.5333\n",
      "Epoch 5/30\n",
      "770/770 [==============================] - 25s - loss: 0.8177 - acc: 0.8052 - val_loss: 1.6846 - val_acc: 0.5485\n",
      "Epoch 6/30\n",
      "770/770 [==============================] - 25s - loss: 0.7274 - acc: 0.8481 - val_loss: 1.6075 - val_acc: 0.5758\n",
      "Epoch 7/30\n",
      "770/770 [==============================] - 25s - loss: 0.6503 - acc: 0.8727 - val_loss: 1.6400 - val_acc: 0.5788\n",
      "Epoch 8/30\n",
      "770/770 [==============================] - 26s - loss: 0.5828 - acc: 0.8987 - val_loss: 1.6241 - val_acc: 0.5818\n",
      "Epoch 9/30\n",
      "770/770 [==============================] - 25s - loss: 0.5125 - acc: 0.9299 - val_loss: 1.6048 - val_acc: 0.6061\n",
      "Epoch 10/30\n",
      "770/770 [==============================] - 25s - loss: 0.4909 - acc: 0.9221 - val_loss: 1.5704 - val_acc: 0.6242\n",
      "Epoch 11/30\n",
      "770/770 [==============================] - 25s - loss: 0.4383 - acc: 0.9468 - val_loss: 1.5666 - val_acc: 0.6273\n",
      "Epoch 12/30\n",
      "770/770 [==============================] - 25s - loss: 0.4178 - acc: 0.9558 - val_loss: 1.6375 - val_acc: 0.5970\n",
      "Epoch 13/30\n",
      "770/770 [==============================] - 25s - loss: 0.4061 - acc: 0.9597 - val_loss: 1.5093 - val_acc: 0.6455\n",
      "Epoch 14/30\n",
      "770/770 [==============================] - 25s - loss: 0.3735 - acc: 0.9662 - val_loss: 1.5535 - val_acc: 0.6394\n",
      "Epoch 15/30\n",
      "770/770 [==============================] - 25s - loss: 0.3546 - acc: 0.9727 - val_loss: 1.5798 - val_acc: 0.6333\n",
      "Epoch 16/30\n",
      "770/770 [==============================] - 25s - loss: 0.3181 - acc: 0.9870 - val_loss: 1.5861 - val_acc: 0.6303\n",
      "Epoch 17/30\n",
      "770/770 [==============================] - 25s - loss: 0.3196 - acc: 0.9779 - val_loss: 1.5513 - val_acc: 0.6303\n",
      "Epoch 18/30\n",
      "770/770 [==============================] - 25s - loss: 0.3087 - acc: 0.9831 - val_loss: 1.4925 - val_acc: 0.6424\n",
      "Epoch 19/30\n",
      "770/770 [==============================] - 25s - loss: 0.2918 - acc: 0.9844 - val_loss: 1.5563 - val_acc: 0.6576\n",
      "Epoch 20/30\n",
      "770/770 [==============================] - 25s - loss: 0.2830 - acc: 0.9883 - val_loss: 1.4957 - val_acc: 0.6364\n",
      "Epoch 21/30\n",
      "770/770 [==============================] - 25s - loss: 0.2676 - acc: 0.9935 - val_loss: 1.4765 - val_acc: 0.6485\n",
      "Epoch 22/30\n",
      "770/770 [==============================] - 25s - loss: 0.2674 - acc: 0.9909 - val_loss: 1.5346 - val_acc: 0.6455\n",
      "Epoch 23/30\n",
      "770/770 [==============================] - 25s - loss: 0.2627 - acc: 0.9883 - val_loss: 1.4932 - val_acc: 0.6636\n",
      "Epoch 24/30\n",
      "770/770 [==============================] - 25s - loss: 0.2454 - acc: 0.9935 - val_loss: 1.4701 - val_acc: 0.6455\n",
      "Epoch 25/30\n",
      "770/770 [==============================] - 25s - loss: 0.2405 - acc: 0.9948 - val_loss: 1.4901 - val_acc: 0.6424\n",
      "Epoch 26/30\n",
      "770/770 [==============================] - 36s - loss: 0.2260 - acc: 0.9987 - val_loss: 1.5152 - val_acc: 0.6455\n",
      "Epoch 27/30\n",
      "770/770 [==============================] - 37s - loss: 0.2304 - acc: 0.9948 - val_loss: 1.5079 - val_acc: 0.6424\n",
      "Epoch 28/30\n",
      "770/770 [==============================] - 25s - loss: 0.2222 - acc: 0.9961 - val_loss: 1.5053 - val_acc: 0.6606\n",
      "Epoch 29/30\n",
      "770/770 [==============================] - 26s - loss: 0.2145 - acc: 0.9961 - val_loss: 1.5163 - val_acc: 0.6485\n",
      "Epoch 30/30\n",
      "770/770 [==============================] - 25s - loss: 0.2112 - acc: 0.9935 - val_loss: 1.4572 - val_acc: 0.6606\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, batch_size = 16, nb_epoch = 30, validation_data = (testX, testY), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss for %d samples per category' % samCat)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy for %d samples per category' % samCat)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_acc: 0.2273 2 sample\n",
    "        0.25  4 sample\n",
    "        0.3182 8 sample\n",
    "        0.4034 16 sample\n",
    "        0.6636 70 sample        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
