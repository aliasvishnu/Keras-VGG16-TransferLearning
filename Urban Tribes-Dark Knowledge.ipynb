{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: Tesla K20c (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.regularizers import l2, activity_l2,l1\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from scipy import misc\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model with VGG16 feature extractors, set trainable false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temperature=2\n",
    "\n",
    "def softmaxTemp(x):\n",
    "    return K.softmax(x/temperature)\n",
    "\n",
    "def getModel( output_dim):\n",
    "    # output_dim: the number of classes (int)\n",
    "    # return: compiled model (keras.engine.training.Model)\n",
    "    \n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    vgg_out = vgg_model.layers[-1].output\n",
    "    \n",
    "    out = Dense( output_dim, activation='softmax')( vgg_out )\n",
    "    \n",
    "    tl_model = Model( input=vgg_model.input, output=out)\n",
    "    \n",
    "    tl_model.layers[-2].activation=softmaxTemp\n",
    "    \n",
    "    for layer in tl_model.layers[0:-1]:\n",
    "        layer.trainable = False            \n",
    "\n",
    "    tl_model.compile(loss= \"categorical_crossentropy\", optimizer=\"adagrad\", metrics=[\"acc\"])\n",
    "    tl_model.summary()\n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all images into 'album'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadImages(path = '/mnt/cube/UT_/Urban_tribes/'):\n",
    "    album = {}\n",
    "    for item in listdir(path):\n",
    "        category = item[0:4]\n",
    "        if category == \".ipy\":\n",
    "            continue\n",
    "        if category not in album:\n",
    "            album[category] = []\n",
    "        \n",
    "        img = load_img(path+item)\n",
    "        img = img_to_array(img)\n",
    "        img = misc.imresize(img, (224, 224))\n",
    "        img = scipy.misc.imrotate(img, 180)\n",
    "        album[category].append(img)\n",
    "    return album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "album = loadImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(album['goth'][0][:, :, 0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 'album' into dataset\n",
    "Album is split into training and testing input/outputs according to number of examples attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dataset(album, numExamples):\n",
    "    trn_inp = []\n",
    "    trn_out = []\n",
    "    tst_inp = []\n",
    "    tst_out = []\n",
    "    keys = album.keys()\n",
    "    for key in keys:\n",
    "        examples = album[key]\n",
    "        l = len(examples)\n",
    "        idx = np.random.choice(l, numExamples+30)\n",
    "        for i in idx[:-5]:\n",
    "            trn_inp.append(examples[i])\n",
    "            trn_out.append(keys.index(key))\n",
    "        for i in idx[-5:]:\n",
    "            tst_inp.append(examples[i])\n",
    "            tst_out.append(keys.index(key))\n",
    "    return [trn_inp, trn_out, tst_inp, tst_out]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(album['bike'][0][:, :, 0])\n",
    "# # plt.show()\n",
    "# album.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(album, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX = np.array(dataset[0])\n",
    "trainY = np.array(dataset[1])\n",
    "\n",
    "# Now shuffle the training data and swapaxes\n",
    "idx = np.random.choice(len(trainX), len(trainX))\n",
    "trainX = trainX[idx]\n",
    "trainY = trainY[idx]\n",
    "\n",
    "trainX = preprocess_input(np.float64(trainX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "\n",
    "# Only swapaxes for testing data\n",
    "testX = np.array(dataset[2])\n",
    "testY = np.array(dataset[3])\n",
    "\n",
    "testX = preprocess_input(np.float64(testX)).swapaxes(1, 3).swapaxes(2, 3)\n",
    "testY = np_utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(trainX[10][0, :, :])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6faa2ca1f58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'getModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = getModel(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1045 samples, validate on 55 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, batch_size = 16, nb_epoch = 30, validation_data = (testX, testY), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
